{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a923666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_state = 42\n",
    "gen = random.Random(random_state)\n",
    "\n",
    "trimmed = False\n",
    "max_w = 1165 if not trimmed else 643# Measured\n",
    "data_dir = '../../allwavs/allvowl/extracted/' + 'trimmed/'*trimmed + 'img/'\n",
    "files = os.listdir(data_dir)\n",
    "use_mel = True\n",
    "files = [file for file in files if ('mel' in file) == use_mel]\n",
    "gen.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70190926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c651a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrumDataset(Dataset):\n",
    "    def __init__(self, data_dir, files):\n",
    "        self.data_dir = data_dir\n",
    "        self.files = [file for file in files if '~' not in file.split('__')[0]]\n",
    "        gen.shuffle(self.files)\n",
    "        self.idx2lbl = ['2', '9', 'a', 'E', 'e', 'i', 'o', 'O', 'u', 'y']\n",
    "        self.lbl2idx = {label: i for i, label in enumerate(self.idx2lbl)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_np = io.imread(self.data_dir + '/' + self.files[idx], as_gray=True)\n",
    "        image_np = np.pad(1 - image_np, [(0, 0), (0, max_w - image_np.shape[1])], mode='constant', constant_values=0)\n",
    "        label = self.files[idx].split('__')[0].replace('E+', 'E').replace('@', '9')\n",
    "        return (torch.tensor(image_np).float(), self.lbl2idx[label])\n",
    "\n",
    "l = len(files)\n",
    "train_size = 0.9\n",
    "cutoff = int(l*train_size)\n",
    "\n",
    "train_set = SpectrumDataset(data_dir, files[:cutoff])\n",
    "test_set = SpectrumDataset(data_dir, files[cutoff:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "928e3ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '6')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im, label = train_set[0]\n",
    "plt.imshow(im.numpy(), cmap='gray')\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c0c96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.cnn_layer1 = nn.Sequential(nn.Conv2d(1, 16, kernel_size=3),\n",
    "                                        nn.ReLU(),\n",
    "                                        #nn.BatchNorm2d(16),\n",
    "                                        nn.MaxPool2d(kernel_size=3))\n",
    "        self.cnn_layer2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=3),\n",
    "                                        nn.ReLU(),\n",
    "                                        #nn.BatchNorm2d(32),\n",
    "                                        nn.MaxPool2d(kernel_size=3))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear_layer1 = nn.Sequential(nn.Linear(32*29*(70 if trimmed else 128), 64),\n",
    "                                           nn.ReLU())\n",
    "        self.linear_layer2 = nn.Sequential(nn.Linear(64, num_classes))\n",
    "        \n",
    "        #self.cnn_layer1 = nn.Sequential(nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "        #                                nn.ReLU(),\n",
    "        #                                #nn.BatchNorm2d(16),\n",
    "        #                                nn.MaxPool2d(kernel_size=5))\n",
    "        #self.cnn_layer2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "        #                                nn.ReLU(),\n",
    "        #                                #nn.BatchNorm2d(32),\n",
    "        #                                nn.MaxPool2d(kernel_size=5))\n",
    "        #self.linear_layer1 = nn.Linear(32*10*25, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out1 = self.cnn_layer1(x)\n",
    "        out2 = self.cnn_layer2(out1)\n",
    "        #out2 = self.dropout(out2)\n",
    "        out_vec = out2.reshape(out2.shape[0], -1)\n",
    "        out = self.linear_layer1(out_vec)\n",
    "        #out2 = self.linear_layer2(out)\n",
    "        return out#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a27de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cnn_classifier(model, eval_dataloader):\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in eval_dataloader:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            y_predicted = model(images)\n",
    "            _, label_predicted = torch.max(y_predicted.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (label_predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def training_cnn_classifier(model, train_dataloader, num_epochs, loss_fn, learning_rate, verbose=True):\n",
    "    model_tr = copy.deepcopy(model)\n",
    "    model_tr.train()\n",
    "    optimizer = torch.optim.SGD(model_tr.parameters(), lr=learning_rate)\n",
    "    loss_all_epochs = []\n",
    "    test_acc_all_epochs = []\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Epoch [0/{num_epochs}], Loss: N/A, Test acc: {eval_cnn_classifier(model_tr, test_dataloader):.4f}%')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        loss_current_epoch = 0\n",
    "        for batch_index, (images, labels) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            pred_labels = model_tr(images)\n",
    "\n",
    "            loss = loss_fn(pred_labels, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_current_epoch += loss.item()\n",
    "        \n",
    "        loss_all_epochs.append(loss_current_epoch)\n",
    "        test_acc = eval_cnn_classifier(model_tr, test_dataloader)\n",
    "        test_acc_all_epochs.append(test_acc)\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss_current_epoch:.4f}, Test acc: {test_acc:.4f}%')\n",
    "        \n",
    "    return model_tr, loss_all_epochs, test_acc_all_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf874c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  7607690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                          | 3/1132 [00:00<00:50, 22.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50], Loss: N/A, Test acc: 0.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:29<00:00, 38.08it/s]\n",
      "  0%|▍                                                                                                          | 4/1132 [00:00<00:30, 36.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 3960.8211, Test acc: 14.2857%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:31<00:00, 35.41it/s]\n",
      "  0%|▍                                                                                                          | 4/1132 [00:00<00:32, 34.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Loss: 3049.8392, Test acc: 28.5714%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:31<00:00, 35.92it/s]\n",
      "  0%|▍                                                                                                          | 4/1132 [00:00<00:34, 32.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Loss: 2309.6128, Test acc: 35.2941%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:30<00:00, 36.61it/s]\n",
      "  0%|▍                                                                                                          | 5/1132 [00:00<00:29, 38.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Loss: 1844.0605, Test acc: 49.5798%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:30<00:00, 36.67it/s]\n",
      "  0%|▍                                                                                                          | 4/1132 [00:00<00:33, 33.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Loss: 1377.4988, Test acc: 50.4202%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:31<00:00, 36.45it/s]\n",
      "  0%|▍                                                                                                          | 4/1132 [00:00<00:31, 35.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Loss: 1123.8291, Test acc: 42.8571%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:31<00:00, 35.90it/s]\n",
      "  0%|▎                                                                                                          | 3/1132 [00:00<00:42, 26.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Loss: 793.4097, Test acc: 50.4202%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:30<00:00, 37.61it/s]\n",
      "  0%|▍                                                                                                          | 4/1132 [00:00<00:30, 36.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Loss: 567.0167, Test acc: 62.1849%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:30<00:00, 36.70it/s]\n",
      "  0%|▍                                                                                                          | 4/1132 [00:00<00:35, 31.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Loss: 399.1148, Test acc: 62.1849%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:30<00:00, 36.99it/s]\n",
      "  0%|▎                                                                                                          | 3/1132 [00:00<00:39, 28.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 330.0544, Test acc: 64.7059%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████▌                                                                                                 | 91/1132 [00:02<00:28, 36.60it/s]"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "train_dataloader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "num_classes = 10\n",
    "model = CNNClassifier(num_classes)\n",
    "\n",
    "print('Total number of parameters: ', \n",
    "      sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model.apply(init_weights)\n",
    "\n",
    "num_epochs = 50\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "\n",
    "model.cuda()\n",
    "model, loss_total, test_acc_total = training_cnn_classifier(model, train_dataloader, num_epochs, loss_fn, learning_rate, verbose=True)\n",
    "\n",
    "torch.save(model.state_dict(), 'model_cnn_classif.pt')\n",
    "plt.plot(loss_total, label='loss')\n",
    "plt.plot([max(loss_total)*(100-x)/100 for x in test_acc_total], label='acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = eval_cnn_classifier(model, test_dataloader)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b001be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lambda Notebook (Python 3)",
   "language": "python",
   "name": "lambda-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
