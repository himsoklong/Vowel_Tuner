{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35dc25cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_state = 42\n",
    "gen = random.Random(random_state)\n",
    "\n",
    "data_dir = '../../allwavs/allvowl/corrected/extracted/img'\n",
    "files = os.listdir(data_dir)\n",
    "use_mel = True\n",
    "files = [file for file in files if ('mel' in file) == use_mel]\n",
    "#max_w = max(io.imread(data_dir + '/' + file).shape[1] for file in files)\n",
    "#print(max_w)\n",
    "gen.shuffle(files)\n",
    "max_w = 31 # Measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac37c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21463565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████                                                                                      | 645/3557 [00:12<00:54, 53.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_522/1945948308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpectrumDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpectrumDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_522/1945948308.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, files)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mphonemes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_gray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manti_aliasing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                (plugin, kind))\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/v2.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mimopen_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"legacy_mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ri\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mimopen_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/imopen.py\u001b[0m in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_hint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<bytes>\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename_zip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename_zip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEXAMPLE_IMAGES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 raise IOError(\n\u001b[1;32m    383\u001b[0m                     \u001b[0;34m\"No such file: %r. This file looks like one of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class SpectrumDataset(Dataset):\n",
    "    def __init__(self, data_dir, files):\n",
    "        self.data_dir = data_dir\n",
    "        self.files = [file for file in files if '~' not in file.split('__')[0]]\n",
    "        gen.shuffle(self.files)\n",
    "        all_phonemes = ['l', 'm', 'p', 's', 't', 't1']\n",
    "        self.data = []\n",
    "        for file in tqdm(self.files):\n",
    "            split = file.split('__')\n",
    "        \n",
    "            gender = split[1]\n",
    "            begin_time = float(split[2])\n",
    "            end_time = float(split[3])\n",
    "            phonemes = split[4].split('_')\n",
    "            \n",
    "            image = io.imread(self.data_dir + '/' + file, as_gray=True)\n",
    "            image = resize(image, (image.shape[0], max_w), anti_aliasing=False)\n",
    "            \n",
    "            label = (begin_time, end_time)\n",
    "            self.data.append((\n",
    "            (torch.tensor(image).float(),\n",
    "             torch.tensor([gender == 'f', len(phonemes) == 2, *[phonemes[0] == x for x in all_phonemes]])\n",
    "            ), torch.tensor(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "l = len(files)\n",
    "train_size = 0.9\n",
    "cutoff = int(l*train_size)\n",
    "\n",
    "train_set = SpectrumDataset(data_dir, files[:cutoff])\n",
    "test_set = SpectrumDataset(data_dir, files[cutoff:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(im, features), label = train_set[0]\n",
    "print(im)\n",
    "print(features)\n",
    "print(label)\n",
    "plt.imshow(im.numpy(), cmap='gray')\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb53d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNRegressor, self).__init__()\n",
    "        \n",
    "        self.cnn_layer1 = nn.Sequential(nn.Conv2d(1, 16, kernel_size=3, padding='valid'),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(0.1),\n",
    "                                        nn.BatchNorm2d(16),\n",
    "                                        nn.MaxPool2d(kernel_size=2))\n",
    "        self.cnn_layer2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=3, padding='valid'),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.BatchNorm2d(32),\n",
    "                                        nn.MaxPool2d(kernel_size=2))\n",
    "        self.linear_layer1 = nn.Linear(32*30*6 + 8, 64)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.activ1 = nn.ReLU()\n",
    "        self.linear_layer_p = nn.Linear(64, 32)\n",
    "        self.dropout_p = nn.Dropout(0.5)\n",
    "        self.activ_p = nn.ReLU()\n",
    "        self.linear_layer2 = nn.Linear(32, 2)\n",
    "        self.activ2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, images, features):\n",
    "        images = images.unsqueeze(1)\n",
    "        \n",
    "        cnn1 = self.cnn_layer1(images)\n",
    "        cnn2 = self.cnn_layer2(cnn1)\n",
    "        cnn_vec = cnn2.reshape(cnn2.shape[0], -1)\n",
    "        cnn_cb = torch.cat((cnn_vec, features), dim=1)\n",
    "        out = self.linear_layer1(cnn_cb)\n",
    "        out = self.activ1(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.linear_layer_p(out)\n",
    "        out = self.dropout_p(out)\n",
    "        out = self.activ_p(out)\n",
    "        out2 = self.linear_layer2(out)\n",
    "        out2 = self.activ2(out2)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf87cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cnn_regressor(model, eval_dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for (images, features), labels in eval_dataloader:\n",
    "            images = images.cuda()\n",
    "            features = features.cuda()\n",
    "            labels = labels.cuda()\n",
    "            y_predicted = model(images, features)\n",
    "            loss = loss_fn(y_predicted, labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss/len(eval_dataloader)\n",
    "\n",
    "def training_cnn_regressor(model, train_dataloader, num_epochs, loss_fn, learning_rate, verbose=True):\n",
    "    model_tr = copy.deepcopy(model)\n",
    "    model_tr.train()\n",
    "    optimizer = torch.optim.AdamW(model_tr.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    loss_all_epochs = []\n",
    "    test_loss_all_epochs = []\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Epoch [0/{num_epochs}], Loss: {100*eval_cnn_regressor(model_tr, train_dataloader, loss_fn):.4f}, Test loss: {100*eval_cnn_regressor(model_tr, test_dataloader, loss_fn):.4f}')\n",
    "    \n",
    "    total = len(train_dataloader)\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_current_epoch = 0\n",
    "        for (images, features), labels in tqdm(train_dataloader, total=total):\n",
    "            images = images.cuda()\n",
    "            features = features.cuda()\n",
    "            labels = labels.cuda()\n",
    "            y_predicted = model_tr(images, features)\n",
    "            loss = loss_fn(y_predicted, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_current_epoch += loss.item()\n",
    "        \n",
    "        loss_all_epochs.append(loss_current_epoch / total)\n",
    "        test_loss = eval_cnn_regressor(model_tr, test_dataloader, loss_fn)\n",
    "        test_loss_all_epochs.append(test_loss)\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {100*loss_current_epoch / total:.4f}, Test loss: {100*test_loss:.4f}')\n",
    "        \n",
    "    return model_tr, loss_all_epochs, test_loss_all_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39580b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_dataloader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "model = CNNRegressor()\n",
    "\n",
    "print('Total number of parameters: ', \n",
    "      sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model.apply(init_weights)\n",
    "\n",
    "num_epochs = 30\n",
    "loss_fn = nn.BCELoss()\n",
    "learning_rate = 0.01\n",
    "\n",
    "model.cuda()\n",
    "model, loss_total, test_loss_total = training_cnn_regressor(model, train_dataloader, num_epochs, loss_fn, learning_rate, verbose=True)\n",
    "\n",
    "torch.save(model.state_dict(), 'model_cnn_classif.pt')\n",
    "plt.plot(loss_total, label='Train loss')\n",
    "plt.plot(test_loss_total, label='Test loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "0a849426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2593, 0.7037]) tensor([0.2760, 0.8862]) 0.01679190993309021 -\n",
      "tensor([0.6296, 1.0000]) tensor([0.4798, 1.0000]) 0.011220752261579037 -\n",
      "tensor([0.7568, 0.9189]) tensor([0.4155, 0.8559]) 0.06022144481539726 ------\n",
      "tensor([0.1200, 1.0000]) tensor([0.3243, 1.0000]) 0.02086157724261284 --\n",
      "tensor([0.5454, 1.0000]) tensor([0.3848, 1.0000]) 0.012901006266474724 -\n",
      "tensor([0.5862, 0.7241]) tensor([0.4845, 0.8930]) 0.01942349784076214 -\n",
      "tensor([0.7727, 1.0000]) tensor([0.6279, 1.0000]) 0.010483020916581154 -\n",
      "tensor([0.4800, 0.8800]) tensor([0.6677, 0.9014]) 0.017850643023848534 -\n",
      "tensor([0.3333, 1.0000]) tensor([0.5074, 1.0000]) 0.015150841325521469 -\n",
      "tensor([0.4688, 0.8125]) tensor([0.4701, 0.9924]) 0.016176696866750717 -\n",
      "tensor([0.2963, 1.0000]) tensor([0.1372, 1.0000]) 0.012660259380936623 -\n",
      "tensor([0.1622, 0.6216]) tensor([0.1117, 0.8230]) 0.02154494822025299 --\n",
      "tensor([0.7667, 1.0000]) tensor([0.5318, 1.0000]) 0.027592910453677177 --\n",
      "tensor([0.2857, 0.4762]) tensor([0.2474, 0.8393]) 0.06665139645338058 ------\n",
      "tensor(0.6937)\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for (im, ft), lb in list(test_dataloader):\n",
    "    im = im.cuda()\n",
    "    ft = ft.cuda()\n",
    "    y_pred = model(im, ft).detach().cpu()[0]\n",
    "    y_true = lb[0]\n",
    "    err = torch.mean((y_true - y_pred)**2)\n",
    "    total += err\n",
    "    out = '-'*int(err*100)\n",
    "    if out:\n",
    "        print(y_true, y_pred, err.item(), out)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "2811681a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNRegressor(\n",
       "  (cnn_layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (cnn_layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (linear_layer1): Linear(in_features=5768, out_features=64, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (activ1): ReLU()\n",
       "  (linear_layer_p): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (dropout_p): Dropout(p=0.5, inplace=False)\n",
       "  (activ_p): ReLU()\n",
       "  (linear_layer2): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (activ2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "2a28bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model4.state_dict(), 'model_cnn_classif.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "c5de34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model4, 'model_cnn_regress.fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda80768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lambda Notebook (Python 3)",
   "language": "python",
   "name": "lambda-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
